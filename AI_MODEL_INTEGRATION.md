# Fine-Tuned AI Model Integration Guide

This document explains how to integrate your fine-tuned AI models with the VibeRehab backend for generating text and audio outputs.

## Overview

The backend now supports custom fine-tuned AI models that can generate both **text** and **audio** outputs simultaneously. The system includes dedicated handlers for:

1. **AI Model Service** - Interfaces with your fine-tuned model API
2. **Audio Handler** - Manages audio file storage and retrieval
3. **Text Handler** - Manages text output storage and logging

## Architecture

```
┌─────────────────┐
│  Frontend/API   │
└────────┬────────┘
         │
         ▼
┌─────────────────────────────────┐
│    Routes (ai.py, audio.py)     │
└────────┬────────────────────────┘
         │
         ▼
┌─────────────────────────────────┐
│   AI Model Service              │◄─── Calls your fine-tuned model API
└────────┬────────────────────────┘
         │
         ├─────────────┬────────────┐
         ▼             ▼            ▼
┌──────────────┐  ┌─────────┐  ┌──────────┐
│ Text Handler │  │  Audio  │  │ Database │
│              │  │ Handler │  │  (opt.)  │
└──────────────┘  └─────────┘  └──────────┘
```

## Services Directory Structure

```
services/
├── __init__.py
├── ai_model_service.py    # Main AI model integration
├── audio_handler.py       # Audio file management
└── text_handler.py        # Text output management
```

## 1. AI Model Service (`ai_model_service.py`)

### Purpose
Interfaces with your fine-tuned AI model API to generate content.

### Configuration

Set these in your `.env` file:
```bash
MODEL_ENDPOINT=http://your-model-server:8000/api/model
MODEL_API_KEY=your_secret_key
```

### Expected Model API Contract

Your fine-tuned model API should accept POST requests to `{MODEL_ENDPOINT}/generate` with this format:

#### Request Format

**For Story Generation:**
```json
{
  "task": "story_generation",
  "context": {
    "user_type": "rehabilitation_patient",
    "content_type": "inspirational_story",
    "max_words": 100,
    "themes": ["patience", "resilience", "small_victories"]
  },
  "parameters": {
    "max_length": 150,
    "temperature": 0.8,
    "output_format": "both"
  }
}
```

**For Schedule Generation:**
```json
{
  "task": "schedule_generation",
  "tasks": ["Knee Stretches", "10-min Walk", "Check Posture"],
  "user_profile": {
    "preferred_wake_time": "8:00 AM",
    "activity_level": "moderate"
  },
  "parameters": {
    "current_time": "9:00 AM",
    "scheduling_rules": {
      "recurring_tasks": ["Check Posture"],
      "preferred_times": {
        "walk": "afternoon",
        "stretches": "after_sitting"
      }
    }
  }
}
```

#### Response Format

**Story Generation Response:**
```json
{
  "text": "Today is a new chapter. Focus not on the mountain...",
  "audio": "<base64_encoded_audio_data>",  // Optional
  "metadata": {
    "model_version": "v1.2",
    "generation_time_ms": 450
  }
}
```

**Schedule Generation Response:**
```json
{
  "schedule": [
    { "time": "11:00 AM", "task": "Check Posture" },
    { "time": "1:00 PM", "task": "Knee Stretches" },
    { "time": "5:00 PM", "task": "10-min Walk" }
  ],
  "metadata": {
    "model_version": "v1.2",
    "source": "fine_tuned"
  },
  "confidence": 0.95
}
```

### Fallback Mechanism

If your model API is unavailable, the service automatically falls back to:
- **Stories**: Pre-written inspirational messages (rotated by time)
- **Schedules**: Rule-based scheduling algorithm

This ensures the application continues functioning during model downtime.

## 2. Audio Handler (`audio_handler.py`)

### Purpose
Manages storage, retrieval, and cleanup of audio files generated by the AI model.

### Features

#### Storage Management
- **Temporary storage**: Auto-cleanup after 24 hours
- **Permanent storage**: Long-term storage for favorites
- Supports formats: WAV, MP3, OGG

#### Audio Operations

**Save Audio:**
```python
from services.audio_handler import AudioHandler

handler = AudioHandler()
info = handler.save_audio(
    audio_data=audio_bytes,
    filename="story_123",  # Optional
    permanent=False,       # Temp or permanent
    format="wav"          # File format
)
# Returns: {filename, path, url, size_kb, created_at, ...}
```

**Retrieve Audio:**
```python
audio_bytes = handler.get_audio("story_123.wav")
```

**List Audio Files:**
```python
files = handler.list_audio_files(permanent_only=False)
```

**Cleanup Temp Files:**
```python
deleted_count = handler.cleanup_temp_files(max_age_hours=24)
```

### Storage Directory Structure

```
audio_outputs/
├── temp/          # Auto-cleaned temporary files
│   ├── audio_uuid1.wav
│   └── audio_uuid2.wav
└── permanent/     # Long-term storage
    ├── story_123.wav
    └── story_456.wav
```

## 3. Text Handler (`text_handler.py`)

### Purpose
Manages text output storage, logging, and formatting.

### Features

#### Text Operations

**Save Story:**
```python
from services.text_handler import TextHandler

handler = TextHandler()
info = handler.save_story(
    story_text="Today is a new chapter...",
    metadata={"user_id": "user123", "context": {...}}
)
# Returns: {id, filename, path, word_count, char_count, ...}
```

**Save Schedule:**
```python
info = handler.save_schedule(
    schedule=[
        {"time": "11:00 AM", "task": "Check Posture"},
        {"time": "1:00 PM", "task": "Knee Stretches"}
    ],
    metadata={"confidence": 0.95}
)
```

**Retrieve by ID:**
```python
story = handler.get_story("abc12345")
schedule = handler.get_schedule("xyz98765")
```

**Generation Logging:**
```python
handler.log_generation(
    generation_type="story",
    success=True,
    metadata={"story_id": "abc123"}
)
```

### Storage Directory Structure

```
text_outputs/
├── stories/       # Generated stories
│   ├── story_20251101_120000_abc123.json
│   └── story_20251101_130000_def456.json
├── schedules/     # Generated schedules
│   ├── schedule_20251101_120000_xyz789.json
│   └── schedule_20251101_140000_uvw012.json
└── logs/          # Generation logs
    ├── generation_log_20251101.json
    └── generation_log_20251102.json
```

## API Endpoints

### Story Generation

**Endpoint:** `GET /api/ai/vibestory`

**Query Parameters:**
- `include_audio` (default: true) - Include audio URL in response
- `save_audio` (default: false) - Save audio permanently

**Response:**
```json
{
  "storyText": "Today is a new chapter...",
  "storyId": "abc123",
  "wordCount": 87,
  "audioUrl": "/api/audio/story_abc123.wav",
  "audioFilename": "story_abc123.wav",
  "audioSize": 245.5,
  "success": true
}
```

### Schedule Generation

**Endpoint:** `POST /api/ai/generateschedule`

**Request Body:**
```json
{
  "tasks": ["Knee Stretches", "10-min Walk", "Check Posture"],
  "user_profile": {
    "preferred_wake_time": "8:00 AM",
    "activity_level": "moderate"
  }
}
```

**Response:**
```json
{
  "schedule": [
    { "time": "11:00 AM", "task": "Check Posture" },
    { "time": "1:00 PM", "task": "Knee Stretches" },
    { "time": "5:00 PM", "task": "10-min Walk" }
  ],
  "scheduleId": "xyz789",
  "taskCount": 5,
  "confidence": 0.95,
  "metadata": { "source": "fine_tuned" },
  "success": true
}
```

### Audio Retrieval

**Endpoint:** `GET /api/audio/{filename}`

Returns the audio file as a stream (WAV/MP3/OGG).

**Example:**
```
GET /api/audio/story_abc123.wav
```

### Audio File Info

**Endpoint:** `GET /api/audio/{filename}/info`

**Response:**
```json
{
  "filename": "story_abc123.wav",
  "path": "/full/path/to/file.wav",
  "size_bytes": 251392,
  "size_kb": 245.5,
  "created_at": "2025-11-01T12:00:00",
  "exists": true
}
```

### List Audio Files

**Endpoint:** `GET /api/audio/list?permanent_only=false`

**Response:**
```json
{
  "files": [
    {
      "filename": "story_abc123.wav",
      "size_kb": 245.5,
      "created_at": "2025-11-01T12:00:00",
      "permanent": false
    }
  ],
  "count": 1
}
```

### Delete Audio File

**Endpoint:** `DELETE /api/audio/{filename}`

**Response:**
```json
{
  "success": true,
  "message": "Audio file story_abc123.wav deleted",
  "filename": "story_abc123.wav"
}
```

### Cleanup Temporary Audio

**Endpoint:** `POST /api/audio/cleanup`

**Request Body (optional):**
```json
{
  "max_age_hours": 24
}
```

**Response:**
```json
{
  "success": true,
  "deleted_count": 15,
  "message": "Cleaned up 15 temporary audio files"
}
```

## Integration Steps

### Step 1: Set Up Your Model API

Ensure your fine-tuned model API is running and accessible:

```bash
# Example: Run your model server
python your_model_server.py --port 8000
```

### Step 2: Configure Environment

Update `.env`:
```bash
MODEL_ENDPOINT=http://localhost:8000/api/model
MODEL_API_KEY=your_secret_key
```

### Step 3: Test Model Connection

```python
from services.ai_model_service import FineTunedModelService

service = FineTunedModelService()
text, audio = service.generate_story({"user_type": "rehabilitation_patient"})
print(f"Generated: {text}")
print(f"Audio available: {audio is not None}")
```

### Step 4: Start the Backend

```bash
python app.py
```

### Step 5: Test API Endpoints

```bash
# Test story generation
curl http://localhost:5000/api/ai/vibestory

# Test schedule generation
curl -X POST http://localhost:5000/api/ai/generateschedule \
  -H "Content-Type: application/json" \
  -d '{"tasks":["Knee Stretches","Walk"]}'
```

## Model Requirements

Your fine-tuned model should:

1. **Accept HTTP POST requests** with JSON payloads
2. **Return JSON responses** with text and optional audio
3. **Support authentication** via Bearer token (optional but recommended)
4. **Handle errors gracefully** with appropriate HTTP status codes
5. **Generate audio** in WAV, MP3, or OGG format (optional)
6. **Encode audio** as base64 string in JSON response

## Example Model Server (Flask)

Here's a minimal example of what your model server might look like:

```python
from flask import Flask, request, jsonify
import your_model_library  # Your fine-tuned model

app = Flask(__name__)

@app.route('/api/model/generate', methods=['POST'])
def generate():
    data = request.json
    task_type = data.get('task')
    
    if task_type == 'story_generation':
        context = data.get('context', {})
        text = your_model_library.generate_story(context)
        audio = your_model_library.text_to_speech(text)  # Optional
        
        return jsonify({
            'text': text,
            'audio': audio,  # base64 encoded
            'metadata': {'model_version': 'v1.0'}
        })
    
    elif task_type == 'schedule_generation':
        tasks = data.get('tasks', [])
        schedule = your_model_library.generate_schedule(tasks)
        
        return jsonify({
            'schedule': schedule,
            'confidence': 0.95,
            'metadata': {'model_version': 'v1.0'}
        })
    
    return jsonify({'error': 'Unknown task type'}), 400

if __name__ == '__main__':
    app.run(port=8000)
```

## Fallback Mode (Without Model API)

The system works even without a model API running. It will:

1. Use pre-written fallback stories
2. Generate schedules using rule-based algorithm
3. Return responses without audio (text only)
4. Continue logging all operations

This is useful for:
- Development without model infrastructure
- Testing frontend integration
- Demo mode at hackathons

## Performance Considerations

### Caching
Consider implementing caching for:
- Similar story requests
- Common scheduling patterns

### Async Processing
For large audio files, consider:
- Background task queues (Celery)
- Async audio generation
- Progressive audio streaming

### Cleanup Jobs
Schedule regular cleanup:
```python
# In production, run as cron job or scheduled task
from services.audio_handler import AudioHandler

handler = AudioHandler()
deleted = handler.cleanup_temp_files(max_age_hours=24)
print(f"Cleaned up {deleted} files")
```

## Monitoring & Logging

All generations are logged to `text_outputs/logs/`:

```json
{
  "timestamp": "2025-11-01T12:00:00",
  "type": "story",
  "success": true,
  "metadata": {
    "story_id": "abc123",
    "generation_time_ms": 450
  }
}
```

Use these logs for:
- Tracking model performance
- Debugging failures
- Usage analytics
- Cost tracking

## Security Considerations

1. **API Keys**: Store in `.env`, never commit to git
2. **Input Validation**: Always validate user inputs
3. **Rate Limiting**: Implement rate limits for expensive operations
4. **File Cleanup**: Regularly clean temporary files
5. **Access Control**: Restrict audio file access to authorized users

## Troubleshooting

### Model API Not Responding
- Check `MODEL_ENDPOINT` in `.env`
- Verify model server is running
- Check firewall/network settings
- Review model server logs

### Audio Not Generated
- Verify model returns audio in response
- Check audio format (WAV/MP3/OGG)
- Verify base64 encoding is correct
- Check audio file permissions

### Text Handler Errors
- Verify write permissions on `text_outputs/`
- Check disk space
- Review file system limits

### Performance Issues
- Enable caching
- Use async processing
- Optimize model inference time
- Consider CDN for audio delivery

## Next Steps

1. Deploy your fine-tuned model API
2. Configure environment variables
3. Test integration thoroughly
4. Implement caching if needed
5. Set up monitoring and alerts
6. Schedule regular cleanup jobs

For questions or issues, refer to the main README.md or create an issue in the project repository.

